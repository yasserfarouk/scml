{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educated-bradford",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T09:29:51.801350Z",
     "iopub.status.busy": "2022-02-16T09:29:51.798642Z",
     "iopub.status.idle": "2022-02-16T09:29:52.916116Z",
     "shell.execute_reply": "2022-02-16T09:29:52.917046Z"
    },
    "papermill": {
     "duration": 1.198538,
     "end_time": "2022-02-16T09:29:52.917479",
     "exception": false,
     "start_time": "2022-02-16T09:29:51.718941",
     "status": "completed"
    },
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# setup disply parameters\n",
    "from matplotlib import pylab as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.ticker import StrMethodFormatter\n",
    "float_formatter = StrMethodFormatter('{x:0.03f}')\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "SMALL_SIZE = 14\n",
    "MEDIUM_SIZE = 16\n",
    "BIGGER_SIZE = 20\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "plt.rc('figure', figsize=(18, 6)) # set figure size\n",
    "plt.rc(\"animation\", html=\"html5\")\n",
    "import random\n",
    "random.seed(0)\n",
    "import numpy as np\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "center-purchase",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T09:29:53.031320Z",
     "iopub.status.busy": "2022-02-16T09:29:53.029914Z",
     "iopub.status.idle": "2022-02-16T09:29:53.688963Z",
     "shell.execute_reply": "2022-02-16T09:29:53.690268Z"
    },
    "papermill": {
     "duration": 0.719781,
     "end_time": "2022-02-16T09:29:53.690557",
     "exception": false,
     "start_time": "2022-02-16T09:29:52.970776",
     "status": "completed"
    },
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loving-variety",
   "metadata": {
    "papermill": {
     "duration": 0.055173,
     "end_time": "2022-02-16T09:29:53.800173",
     "exception": false,
     "start_time": "2022-02-16T09:29:53.745000",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Developing an agent for SCML2024 (Standard)\n",
    "\n",
    "In 2024, we introduced a new implementation of the SCML-Standard track which simplified its API making it exactly the same as the simpler SCML-OneShot track. The older version of the game is not supported anymore.\n",
    "\n",
    "**SCML-OneShot brief introduction** Please refer to the first tutorial for a brief introduction about the world simulated in this game as well as pointers to more information. We will assume knowledge of at least this brief introduction in the remainder of this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "provincial-festival",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T09:29:53.951253Z",
     "iopub.status.busy": "2022-02-16T09:29:53.942463Z",
     "iopub.status.idle": "2022-02-16T09:29:57.340239Z",
     "shell.execute_reply": "2022-02-16T09:29:57.341204Z"
    },
    "papermill": {
     "duration": 3.476978,
     "end_time": "2022-02-16T09:29:57.341465",
     "exception": false,
     "start_time": "2022-02-16T09:29:53.864487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import random\n",
    "from negmas import ResponseType, SAOResponse\n",
    "from scml.std import *\n",
    "from scml.std.common import is_system_agent\n",
    "from pprint import pprint\n",
    "\n",
    "def try_agent(agent_type, n_processes=3, **kwargs):\n",
    "    \"\"\"Runs an agent in a world simulation against a randomly behaving agent\"\"\"\n",
    "    return try_agents([GreedyStdAgent, SyncRandomStdAgent, agent_type], n_processes,**kwargs)\n",
    "\n",
    "def try_agents(agent_types, n_processes=3, n_trials=5, draw=True, agent_params=None, year=2024):\n",
    "    \"\"\"\n",
    "    Runs a simulation with the given agent_types, and n_processes n_trial times.\n",
    "    Optionally also draws a graph showing what happened\n",
    "    \"\"\"\n",
    "    type_scores = defaultdict(float)\n",
    "    counts = defaultdict(int)\n",
    "    agent_scores = dict()\n",
    "    for _ in range(n_trials):\n",
    "        p = n_processes if isinstance(n_processes, int) else random.randint(*n_processes)\n",
    "        cls = {2024: SCML2024StdWorld}[year]\n",
    "        world = cls(\n",
    "            **cls.generate(agent_types, agent_params=agent_params, n_steps=10, \n",
    "            n_processes=p, random_agent_types=True), construct_graphs=True\n",
    "        )\n",
    "        world.run()\n",
    "\n",
    "        all_scores = world.scores()\n",
    "        for aid, agent in world.agents.items():\n",
    "            if is_system_agent(aid):\n",
    "                continue\n",
    "            key = aid if n_trials == 1 else f\"{aid}@{world.id[:4]}\"\n",
    "            agent_scores[key] = (\n",
    "                 agent.type_name.split(':')[-1].split('.')[-1],\n",
    "                 all_scores[aid],\n",
    "                 '(bankrupt)' if world.is_bankrupt[aid] else ''\n",
    "                )\n",
    "        for aid, agent in world.agents.items():\n",
    "            if is_system_agent(aid):\n",
    "                continue\n",
    "            type_ = agent.type_name.split(':')[-1].split('.')[-1]\n",
    "            type_scores[type_] += all_scores[aid]\n",
    "            counts[type_] += 1\n",
    "    type_scores = {k: v/counts[k] if counts[k] else v for k, v in type_scores.items()}\n",
    "    if draw:\n",
    "        world.draw(\n",
    "            what=[\"contracts-concluded\"],\n",
    "            steps=(0, world.n_steps - 1),\n",
    "            together=True, ncols=1, figsize=(20, 20)\n",
    "        )\n",
    "        plt.show()\n",
    "\n",
    "    return world, agent_scores, type_scores\n",
    "\n",
    "def analyze_contracts(world):\n",
    "    \"\"\"\n",
    "    Analyzes the contracts signed in the given world\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    data = pd.DataFrame.from_records(world.saved_contracts)\n",
    "    return data.groupby([\"seller_name\", \"buyer_name\"])[[\"quantity\", \"unit_price\"]].mean()\n",
    "\n",
    "\n",
    "def print_agent_scores(agent_scores):\n",
    "    \"\"\"\n",
    "    Prints scores of individiual agent instances\n",
    "    \"\"\"\n",
    "    for aid, (type_, score, bankrupt) in agent_scores.items():\n",
    "        print(f\"Agent {aid} of type {type_} has a final score of {score} {bankrupt}\")\n",
    "\n",
    "def print_type_scores(type_scores):\n",
    "    \"\"\"Prints scores of agent types\"\"\"\n",
    "    pprint(sorted(tuple(type_scores.items()), key=lambda x: -x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latest-cinema",
   "metadata": {
    "papermill": {
     "duration": 0.060109,
     "end_time": "2022-02-16T09:29:57.462946",
     "exception": false,
     "start_time": "2022-02-16T09:29:57.402837",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now we are ready to develop a do-nothing agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solved-puzzle",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T09:29:57.595442Z",
     "iopub.status.busy": "2022-02-16T09:29:57.593544Z",
     "iopub.status.idle": "2022-02-16T09:30:04.697469Z",
     "shell.execute_reply": "2022-02-16T09:30:04.698622Z"
    },
    "papermill": {
     "duration": 7.178563,
     "end_time": "2022-02-16T09:30:04.698891",
     "exception": false,
     "start_time": "2022-02-16T09:29:57.520328",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MyStdDoNothing(StdPolicy):\n",
    "    \"\"\"My Agent that does nothing\"\"\"\n",
    "    def act(self, state):\n",
    "        return { partner: SAOResponse(ResponseType.END_NEGOTIATION, None)\n",
    "                for partner in state.my_suppliers + state.my_consumers}\n",
    "    \n",
    "world, ascores, tscores = try_agent(MyStdDoNothing, n_trials=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expected-assets",
   "metadata": {
    "papermill": {
     "duration": 0.069602,
     "end_time": "2022-02-16T09:30:04.918782",
     "exception": false,
     "start_time": "2022-02-16T09:30:04.849180",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In all of the graph representing world simulations, we use short names that represent the type of the agent. For example an agent named `01Gr@0` is an agent of type `GreedyStdAgent` at production level 1 that was the third agent to create. `MSD` here is a shorthand for `MyStdDoNothingAgent`.\n",
    "\n",
    "Looking at the `contracts-concluded`, we can see that none of the concluded contracts involved our do-nothing agent. Nevertheless, these agents still had *exogenous contracts* which means that they will lose money. A do-nothing agent will usually lose money in this game.\n",
    "\n",
    "Let's check the scores of different agents to confirm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strong-destination",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T09:30:05.222996Z",
     "iopub.status.busy": "2022-02-16T09:30:05.215831Z",
     "iopub.status.idle": "2022-02-16T09:30:05.231790Z",
     "shell.execute_reply": "2022-02-16T09:30:05.219204Z"
    },
    "papermill": {
     "duration": 0.220667,
     "end_time": "2022-02-16T09:30:05.232757",
     "exception": false,
     "start_time": "2022-02-16T09:30:05.012090",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "print_agent_scores(ascores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brilliant-kazakhstan",
   "metadata": {
    "papermill": {
     "duration": 0.091497,
     "end_time": "2022-02-16T09:30:05.477651",
     "exception": false,
     "start_time": "2022-02-16T09:30:05.386154",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Notice that our do-nothing agent always loses money. That is because it cannot get any contracts from negotiation to satisfy its needs from the exogenous contracts but it still has to pay for disposal cost and shortfall penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italic-hearts",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T09:30:05.661245Z",
     "iopub.status.busy": "2022-02-16T09:30:05.658190Z",
     "iopub.status.idle": "2022-02-16T09:30:05.667061Z",
     "shell.execute_reply": "2022-02-16T09:30:05.659424Z"
    },
    "papermill": {
     "duration": 0.111959,
     "end_time": "2022-02-16T09:30:05.667496",
     "exception": false,
     "start_time": "2022-02-16T09:30:05.555537",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print_type_scores(tscores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "altered-lafayette",
   "metadata": {
    "papermill": {
     "duration": 0.091112,
     "end_time": "2022-02-16T09:30:05.829948",
     "exception": false,
     "start_time": "2022-02-16T09:30:05.738836",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can also have a look at the *exogenous* contracts that drive the market."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disciplinary-christmas",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T09:30:06.084973Z",
     "iopub.status.busy": "2022-02-16T09:30:06.079686Z",
     "iopub.status.idle": "2022-02-16T09:30:06.107856Z",
     "shell.execute_reply": "2022-02-16T09:30:06.109162Z"
    },
    "papermill": {
     "duration": 0.158261,
     "end_time": "2022-02-16T09:30:06.113084",
     "exception": false,
     "start_time": "2022-02-16T09:30:05.954823",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "analyze_contracts(world)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inside-remains",
   "metadata": {
    "papermill": {
     "duration": 0.093199,
     "end_time": "2022-02-16T09:30:06.295245",
     "exception": false,
     "start_time": "2022-02-16T09:30:06.202046",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "There are few things to note about the distribution of the *exogenous* contracts:\n",
    "\n",
    "- The unit price of the raw material is always lower than that of the final product. This is the source of profitability in this market.\n",
    "- Each agent has a different mean and standar deviation for the quantities in its exogenous contracts. This means that different agents will have different utility functions but these utility functions for different steps are related because the exogenous contract is sampled from some common distribution for each agent for all the steps which makes learning more useful in the game."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consolidated-dispatch",
   "metadata": {
    "papermill": {
     "duration": 0.089916,
     "end_time": "2022-02-16T09:30:06.496089",
     "exception": false,
     "start_time": "2022-02-16T09:30:06.406173",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Building your own agent\n",
    "\n",
    "A standard agent needs only to do negotiation. The simplest possible version (`MyDoNothingAgent` above) just responded to offers from its partners and proposed new offers to them.\n",
    "\n",
    "#### Your AWI\n",
    "\n",
    "As described in a [previous tutorial](https://scml.readthedocs.io/en/latest/tutorials/01.run_scml2020.html), your agent can sense and act in the simulation by accessing methods and properties of its AWI which is accessible at any time as:\n",
    "\n",
    "```python\n",
    "self.awi\n",
    "```\n",
    "\n",
    "You can see all of these methods and properties specific for the **StdAWI** and its descendents [here](https://scml.readthedocs.io/en/latest/api/scml.std.StdAWI.html).\n",
    "\n",
    "#### Your ufun\n",
    "\n",
    "The Std game has the advantage that it is possible at the end of each simulation step (day) to calculate **exactly** the profit you will be getting for the set of contracts you have (either through negotiation or as exogenous contracts). We provide a utility function class ([StdUtilityFunction](https://scml.readthedocs.io/en/latest/api/scml.std.StdUFun.html) which can be used normally as any NegMAS [UtilityFunction](http://www.yasserm.com/negmas/api/negmas.preferences.UtilityFunction.html). This ufun is available to your all the time (a new one is created for each simulation step) and is accessible as:\n",
    "\n",
    "```python\n",
    "self.ufun\n",
    "```\n",
    "\n",
    "The most important services this ufun class provides for you are the following:\n",
    "\n",
    "- `from_offers`: This method receives a list of outcomes and a list of booleans indicating whether each of them is for buying or for selling. It returns to you the profit you will get if all of these outcomes _and nothing else_ became contracts. An outcome is just a tuple (quantity, delivery time, unit price). You can use this callback during negotiation to judge hypothetical agreements with your partners. **Note that only offers to be delivered today will be considered**\n",
    "- `from_contracts`: This method is the same as `from_offers` but it receives a list of `Contract` objects. It is useful after all negotiations are finished to calculate the profit you will be getting for this step. **Note that only contracts to be delivered today will be considered**\n",
    "- `is_breach`: will tell you whether or not getting the given total input and output quantities will make you cause a breach. Notice that breaches are expected in the Standard track as any mismatch in the quantities of inputs and outputs will constitute a breach.\n",
    "- `breach_level`: returns a value between zero and one specifying the level of breach that will be recorded for a given total input and output quantities.\n",
    "- `find_limit`: finds either the maximum or the minimum possible profit (minimum profit is maximum loss) attainable in the current simulation step (day). This is useful when you want to normalize utility values between zero and one. Two of the agents we will develop during this tutorial will use this feature.\n",
    "- `max_utility`, `min_utility`: give the maximum and minimum utilities/profits attainable. Note that you must prepare them by calling `find_limit`. We will go into how to do that later.\n",
    "- `best`, `worst`: give more information about the cases of maximum and minimum profit (i.e. the total input and output quantity needed, the prodcible quantity, best possible prices for buying and selling, etc). Again, these are not available except after calling `find_limit`.\n",
    "\n",
    "#### Your callbacks\n",
    "\n",
    "Your agent needs to implement methods that are called by the system at various time during the negotiation. You can find a full list in the [game description](https://yasserfarouk.github.io/files/scml/y2024/scml2024.pdf).\n",
    "\n",
    "The most important ones are:\n",
    "\n",
    "- `init()` called once at the beginning of the simulation (i.e. before the first day starts). At this point, your AWI is set but you should not assume anything else.\n",
    "- `before_step()` called at the **beginning** of _every day_. At this point, your `ufun` is set and market information is available.\n",
    "- `step()` called at the **end** of _every day_. You can use this to analyze what happened during the day and modify your strategy in the future.\n",
    "- `on_negotiation_success()`/`on_negotiation_failure()` called after each negotiation is concluded to let you know what happened in it.\n",
    "- Depending on your base-class, you will also need to implement methods that allow you to control negotiations. These will be explained in details in the following sections but here is a summary:\n",
    "  - **StdAgent** If your agent is based on `StdAgent`, you will get a `propose()` call when you need to offer something to one of our partners during negotiation and `respond()` when asked to respond to one of its offers.\n",
    "  - **StdSyncAgent** If your agent is based on `StdSyncAgent` you will get a call to `first_proposals()` once every day to set your first proposal in all negotiations and a `counter_all()` call to counter offers from your partners. The system will try to always give you one offer from each partner in the `counter_all()` call but that is not guaranteed and sometimes it may be called with a subset of the offers.\n",
    "  - **StdSingleAgreementAgent** If your agent is based on `StdSingleAgreementAgent` you will have to implement `is_acceptable()` to decide if a given offer is acceptable to you, `best_offer()` to find the _best_ offer in a given negotiation for your agent and `is_better()` to compare two offers. Once you implement these, the agent will implement all callback for you trying to get **a single** agreement that maximizes your utility. Note that, again, it is not guaranteed that you will get a single agreement at the end but the system will try its best to achieve that.\n",
    "\n",
    "Now we can start working on our agent.\n",
    "\n",
    "There are three base classes for one-shot agents (`StdAgent`, `SyncStdAgent`, and `StdSingleAgreementAgent`). We will discuss them in more details in what follows.\n",
    "\n",
    "### StdAgent\n",
    "\n",
    "This is the base class of all agents for SCML-Std. Both `SyncStdAgent` and `SingleAgreementStdAgent` inherit from this class and provide support for a simplified way of developing your agent (or so we think). It is perfectly OK to use `StdAgent` directly as the base of your agent.\n",
    "\n",
    "We have already seen the `StdAgent` class for which you need to override `propose` and may also override `respond` to handle negotiations independently. The `propose` method receives the negotiation state (an object of the type `SAOState` including among other things the current negotiation step, relative time, last offer, etc) and is required to return an `Outcome` (See `negmas` documentation) as an offer. The `respond` method receives a negotiation state and an offer (`Outcome`) from the opponent and needs to respond to it by a decision from the `ResponseType` enumeration (`REJECT_OFFER`, `ACCEPT_OFFER`, and `END_NEGOTIATION`). Other than these two negotiation related callbacks, the agent receives an `init` call just after it joins the simulatin and a `step` call after each step. The agent is also informed about failure/success of negotiations through the `on_negotiation_success`/`on_negotiation_failure` callbacks. That is all. A one-shot agent needs to only think about what should it do to respond to each of these six callbacks. All of these callbacks except `propose` are optional.\n",
    "\n",
    "#### Simple StdAgent\n",
    "\n",
    "We have already seen how to develop a do-nothing agent using the `StdAgent` class. Let's try to develop some more meaningful agent using the same base class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "accessory-character",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T09:30:06.730826Z",
     "iopub.status.busy": "2022-02-16T09:30:06.728797Z",
     "iopub.status.idle": "2022-02-16T09:30:13.776332Z",
     "shell.execute_reply": "2022-02-16T09:30:13.777561Z"
    },
    "papermill": {
     "duration": 7.208657,
     "end_time": "2022-02-16T09:30:13.777839",
     "exception": false,
     "start_time": "2022-02-16T09:30:06.569182",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'StdAgent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mSimpleAgent\u001b[39;00m(\u001b[43mStdAgent\u001b[49m):\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"A greedy agent based on StdAgent\"\"\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpropose\u001b[39m(\u001b[38;5;28mself\u001b[39m, negotiator_id: \u001b[38;5;28mstr\u001b[39m, state) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutcome\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'StdAgent' is not defined"
     ]
    }
   ],
   "source": [
    "class SimpleAgent(StdAgent):\n",
    "    \"\"\"A greedy agent based on StdAgent\"\"\"\n",
    "\n",
    "    def propose(self, negotiator_id: str, state) -> \"Outcome\":\n",
    "        return self.best_offer(negotiator_id)\n",
    "\n",
    "    def respond(self, negotiator_id, state, source=''):\n",
    "        offer = state.current_offer\n",
    "        return (\n",
    "            ResponseType.ACCEPT_OFFER\n",
    "            if offer[QUANTITY] <= self._needed(negotiator_id)\n",
    "            else ResponseType.REJECT_OFFER\n",
    "        )\n",
    "\n",
    "    def best_offer(self, negotiator_id):\n",
    "        ami = self.get_nmi(negotiator_id)\n",
    "        if not ami:\n",
    "            return None\n",
    "        my_needs = self._needed(negotiator_id)\n",
    "        if my_needs <= 0:\n",
    "            return self.best_future_offer(ami, negotiator_id)\n",
    "        quantity_issue = ami.issues[QUANTITY]\n",
    "        unit_price_issue = ami.issues[UNIT_PRICE]\n",
    "        offer = [-1] * 3\n",
    "        offer[QUANTITY] = max(\n",
    "            min(my_needs, quantity_issue.max_value),\n",
    "            quantity_issue.min_value\n",
    "        )\n",
    "        offer[TIME] = self.awi.current_step\n",
    "        if self._is_selling(ami):\n",
    "            offer[UNIT_PRICE] = unit_price_issue.max_value\n",
    "        else:\n",
    "            offer[UNIT_PRICE] = unit_price_issue.min_value\n",
    "        return tuple(offer)\n",
    "    \n",
    "    def best_future_offer(self, ami, negotiator_id):\n",
    "        time_issue = ami.issues[TIME]\n",
    "        times = list(time_issue.all)\n",
    "        random.shuffle(times)\n",
    "        for t in times:\n",
    "            needed = self._future_needs(negotiator_id, t)\n",
    "            if needed <= 0:\n",
    "                continue\n",
    "            offer = [-1] * 3\n",
    "            quantity_issue = ami.issues[QUANTITY]\n",
    "            unit_price_issue = ami.issues[UNIT_PRICE]\n",
    "            mx = max(\n",
    "                min(needed, quantity_issue.max_value), quantity_issue.min_value\n",
    "            )\n",
    "            # never contract offer more than production capacity\n",
    "            mx = max(0, min(mx, self.awi.n_lines * (t - self.awi.current_step)))\n",
    "            if mx < 1:\n",
    "                continue\n",
    "            offer[QUANTITY] = random.randint(\n",
    "                max(1, int(0.5 + mx * self.awi.current_step / self.awi.n_steps)), mx\n",
    "            )\n",
    "            offer[TIME] = t\n",
    "            if self._is_selling(ami):\n",
    "                offer[UNIT_PRICE] = unit_price_issue.max_value\n",
    "            else:\n",
    "                offer[UNIT_PRICE] = unit_price_issue.min_value\n",
    "            return tuple(offer)\n",
    "        return None\n",
    "\n",
    "    \n",
    "    def is_seller(self, negotiator_id):\n",
    "        return negotiator_id in self.awi.current_negotiation_details[\"sell\"].keys()\n",
    "\n",
    "    def _needed(self, negotiator_id=None):\n",
    "        if self.awi.is_middle_level:\n",
    "            return self.awi.n_lines\n",
    "        return self.awi.needed_sales if self.is_seller(negotiator_id) else self.awi.needed_supplies\n",
    "    \n",
    "    def _future_needs(self, negotiator_id, t):\n",
    "        return self.awi.n_lines - sum(\n",
    "            (\n",
    "                self.awi.future_sales\n",
    "                if negotiator_id in self.awi.my_consumers\n",
    "                else self.awi.future_supplies\n",
    "            )\n",
    "            .get(t, dict())\n",
    "            .values()\n",
    "        )\n",
    "\n",
    "    \n",
    "    def _is_selling(self, ami):\n",
    "        return ami.annotation[\"product\"] == self.awi.my_output_product\n",
    "    \n",
    "world, ascores, tscores = try_agent(SimpleAgent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worse-covering",
   "metadata": {
    "papermill": {
     "duration": 0.068289,
     "end_time": "2022-02-16T09:30:13.913790",
     "exception": false,
     "start_time": "2022-02-16T09:30:13.845501",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's see how well did this agent behave:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "democratic-representative",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T09:30:14.068449Z",
     "iopub.status.busy": "2022-02-16T09:30:14.066418Z",
     "iopub.status.idle": "2022-02-16T09:30:14.072768Z",
     "shell.execute_reply": "2022-02-16T09:30:14.071994Z"
    },
    "papermill": {
     "duration": 0.087918,
     "end_time": "2022-02-16T09:30:14.073098",
     "exception": false,
     "start_time": "2022-02-16T09:30:13.985180",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "print_type_scores(tscores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustained-lease",
   "metadata": {
    "papermill": {
     "duration": 0.167556,
     "end_time": "2022-02-16T09:30:14.330093",
     "exception": false,
     "start_time": "2022-02-16T09:30:14.162537",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This simple agent is better than the random agent. Let's understand how it works:\n",
    "\n",
    "The main idea of this agent is pretty simple. It tries to *secure* as much of its needs (sales/supplies) as possible in every negotiation at the best possible price for itself.\n",
    "\n",
    "To achieve this goal, the agent uses the fact that the `AWI` already keeps track of this information as `needed_supplies` and `needed_sales`.\n",
    "Therefore, it defines a helper that calculates the amount it needs by subtracting the exogenous quantity it has from the amount it secured\n",
    "\n",
    "```python\n",
    "def _needed(self):\n",
    "    self.awi.needed_sales if self.is_seller(negotiator_id) else self.awi.needed_supplies\n",
    "```\n",
    "\n",
    "where it uses `needed_sales` if the current negotiation is for selling and `needed_supplies` otherwise. Now that the agent can calculate how much it needs to buy/sell, it implements the negotiation related call-backs (`propose` and `respond`). \n",
    "\n",
    "Here is the full implementation of `propose`:\n",
    "```python\n",
    "def propose(self, negotiator_id: str, state) -> \"Outcome\":\n",
    "        return self.best_offer(negotiator_id)\n",
    "```\n",
    "\n",
    "The agent is always offering its best offer which is calculated in the `best_offer` method to be discussed later. It does not conceed at all.\n",
    "\n",
    "Responding to opponent offers is also simple:\n",
    "\n",
    "- it starts by calculating its needs using the helper `_needed`, and ends the negotiation if it needs no more sales/supplies\n",
    "```python\n",
    "    my_needs = self._needed()\n",
    "    if my_needs <= 0:\n",
    "        return ResponseType.END_NEGOTIATION\n",
    "```\n",
    "- If the offered quantity is less than its needs, accept the offer. Otherwise reject the offer.\n",
    "```python\n",
    "    return ResponseType.ACCEPT_OFFER if offer[QUANTITY] <= my_needs else ResponseType.REJECT_OFFER\n",
    "```\n",
    "\n",
    "Most of the code is in the `best_offer` method which calculates the best offer for a negotiation *given the agreements reached so far*. Let's check it line by line:\n",
    "\n",
    "- The agent checks its needs and returns `None` ending the negotiation if it needs no more sales/supplies. We also get access to the AMI.\n",
    "```python\n",
    "    my_needs = self._needed()\n",
    "    if my_needs <= 0:\n",
    "        return None\n",
    "    ami = self.get_nmi(negotiator_id)\n",
    "    if not ami:\n",
    "        return None\n",
    "```\n",
    "\n",
    "- It then finds out the `Issue` objects corresponding to the quantity and unit-price for this negotiation and initializes an offer (we have 3 issues)\n",
    "```python\n",
    "    quantity_issue = ami.issues[QUANTITY]\n",
    "    unit_price_issue = ami.issues[UNIT_PRICE]\n",
    "    offer = [-1] * 3\n",
    "```\n",
    "- The time is always the current step. \n",
    "```python    \n",
    "    offer[TIME] = self.awi.current_step\n",
    "```\n",
    "- The quantity to offer is simply the needs of the agent without mapped within the range of the quantities in the negotiation agenda (note that this may lead the agent to buy more than its needs). \n",
    "```python    \n",
    "    offer[QUANTITY] = max(\n",
    "        min(my_needs, quantity_issue.max_value), quantity_issue.min_value\n",
    "    )\n",
    "```\n",
    "- Finally, the unit price is the maximum possible unit price if the agent is selling otherwise it is the minimum possible price. Note that `is_selling()` assumes that the agent will never find itself in a middle layer in a deep negotiation. We will alleviate this issue later. \n",
    "```python\n",
    "    if self._is_selling(ami):\n",
    "        offer[UNIT_PRICE] = unit_price_issue.max_value\n",
    "    else:\n",
    "        offer[UNIT_PRICE] = unit_price_issue.min_value\n",
    "    return tuple(offer)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mighty-efficiency",
   "metadata": {
    "papermill": {
     "duration": 0.071738,
     "end_time": "2022-02-16T09:30:14.496587",
     "exception": false,
     "start_time": "2022-02-16T09:30:14.424849",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### A (suposedly) better greedy agent\n",
    "\n",
    "One problem with our `SimpleAgent` is that it does not take price into account in two ways:\n",
    "\n",
    "- When asked to `propose`, it *always* proposes an offer with the best price for itself. It **never concedes** on prices. In many cases this will lead to disagreement.\n",
    "- When asked to `respond` to an offer, *it does not even check the price*. This may lead to bad agreements (i.e. very high buying prices/very low selling prices).\n",
    "\n",
    "We will try to remedie both of these issues in the following agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loaded-albert",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T09:30:14.703813Z",
     "iopub.status.busy": "2022-02-16T09:30:14.700493Z",
     "iopub.status.idle": "2022-02-16T09:30:21.586632Z",
     "shell.execute_reply": "2022-02-16T09:30:21.587368Z"
    },
    "papermill": {
     "duration": 7.000913,
     "end_time": "2022-02-16T09:30:21.587607",
     "exception": false,
     "start_time": "2022-02-16T09:30:14.586694",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BetterAgent(SimpleAgent):\n",
    "    \"\"\"A greedy agent based on OneShotAgent with more sane strategy\"\"\"\n",
    "    \n",
    "    def __init__(self, *args, concession_exponent=0.2, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self._e = concession_exponent\n",
    "\n",
    "    def propose(self, negotiator_id: str, state) -> \"Outcome\":\n",
    "        offer = super().propose(negotiator_id, state)\n",
    "        if not offer:\n",
    "            return None\n",
    "        offer = list(offer)\n",
    "        offer[UNIT_PRICE] = self._find_good_price(\n",
    "            self.get_nmi(negotiator_id), state\n",
    "        )        \n",
    "        return tuple(offer)\n",
    "\n",
    "    def respond(self, negotiator_id, state, source=''):\n",
    "        offer = state.current_offer\n",
    "        if offer is None:\n",
    "            return ResponseType.REJECT_OFFER\n",
    "        response = super().respond(negotiator_id, state, source)\n",
    "        if response != ResponseType.ACCEPT_OFFER:\n",
    "            return response\n",
    "        ami = self.get_nmi(negotiator_id)\n",
    "        return (\n",
    "            response if\n",
    "            self._is_good_price(ami, state, offer[UNIT_PRICE])\n",
    "            else ResponseType.REJECT_OFFER\n",
    "        )\n",
    "        \n",
    "    def _is_good_price(self, ami, state, price):\n",
    "        \"\"\"Checks if a given price is good enough at this stage\"\"\"\n",
    "        mn, mx = self._price_range(ami)\n",
    "        th = self._th(state.step, ami.n_steps)        \n",
    "        # a good price is one better than the threshold\n",
    "        if self._is_selling(ami):\n",
    "            return (price - mn) >= th * (mx - mn)\n",
    "        else:\n",
    "            return (mx - price) >= th * (mx - mn)\n",
    "    \n",
    "    def _find_good_price(self, ami, state):\n",
    "        \"\"\"Finds a good-enough price conceding linearly over time\"\"\"        \n",
    "        mn, mx = self._price_range(ami)\n",
    "        th = self._th(state.step, ami.n_steps)\n",
    "        # offer a price that is around th of your best possible price\n",
    "        if self._is_selling(ami):\n",
    "            return mn + th * (mx - mn)\n",
    "        else:\n",
    "            return mx - th * (mx - mn)\n",
    "    \n",
    "    def _price_range(self, ami):\n",
    "        \"\"\"Finds the minimum and maximum prices\"\"\"\n",
    "        mn = ami.issues[UNIT_PRICE].min_value\n",
    "        mx = ami.issues[UNIT_PRICE].max_value           \n",
    "        return mn, mx\n",
    "    \n",
    "    def _th(self, step, n_steps):\n",
    "        \"\"\"calculates a descending threshold (0 <= th <= 1)\"\"\"\n",
    "        return ((n_steps - step - 1) / (n_steps - 1)) ** self._e    \n",
    "        \n",
    "world, ascores, tscores = try_agent(BetterAgent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classified-ordinance",
   "metadata": {
    "papermill": {
     "duration": 0.076589,
     "end_time": "2022-02-16T09:30:21.739501",
     "exception": false,
     "start_time": "2022-02-16T09:30:21.662912",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's see how well did this agent behave:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finished-tunisia",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T09:30:21.914776Z",
     "iopub.status.busy": "2022-02-16T09:30:21.912582Z",
     "iopub.status.idle": "2022-02-16T09:30:21.922501Z",
     "shell.execute_reply": "2022-02-16T09:30:21.921782Z"
    },
    "papermill": {
     "duration": 0.107971,
     "end_time": "2022-02-16T09:30:21.922713",
     "exception": false,
     "start_time": "2022-02-16T09:30:21.814742",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "print_type_scores(tscores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cordless-marriage",
   "metadata": {
    "papermill": {
     "duration": 0.072474,
     "end_time": "2022-02-16T09:30:22.083417",
     "exception": false,
     "start_time": "2022-02-16T09:30:22.010943",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "It seems that `BetterAgent` is getting a score that is not any better than `SimpleAgent`. Let's dive into the agent and analyze how it works:\n",
    "\n",
    "The main idea in `BetterAgent` is to treat the *price* issue separately to avoid the two issues presented earlier:\n",
    "\n",
    "- **Never conceding during proposal** This is solved in the `propose` method by just overriding the price with a `good-enough` price:\n",
    "  ```python\n",
    "    offer[UNIT_PRICE] = self._find_good_price(\n",
    "            self.get_nmi(negotiator_id), state\n",
    "        )        \n",
    "  ```\n",
    "  As an aside, notice that we needed to convert the offer to a list in order to overwrite the price then back into a tuple to send it to the partner.\n",
    "- **Never checking prices of offers** This is solved in the `respond` method by checking whether or not the price offered is a `good-enough` price:\n",
    "  ```python\n",
    "    return (\n",
    "            response if\n",
    "            self._is_good_price(ami, state, offer[UNIT_PRICE])\n",
    "            else ResponseType.REJECT_OFFER\n",
    "        )\n",
    "  ```\n",
    "\n",
    "\n",
    "What we mean by a `good-enough` price is defined in `_is_good_price` and `_find_good_price` methods. Both start by getting the limits of the unit-price in the negotiation agenda and a threshold value ```th```:\n",
    "\n",
    "```python\n",
    "mn, mx = self._price_range(ami, state)\n",
    "th = self._th(mn, mx, state.step, ami.n_steps)\n",
    "```\n",
    "\n",
    "The price range is clear enough. For the threshold ```th``` is a value that starts at $1.0$ and goes down toward $0.0$ over the negotiation time under the control of an agent specific parameter ```_e``` called the concession exponent.\n",
    "Let's see how does this look for different concession exponents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trained-tribe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T09:30:22.437954Z",
     "iopub.status.busy": "2022-02-16T09:30:22.435425Z",
     "iopub.status.idle": "2022-02-16T09:30:23.490858Z",
     "shell.execute_reply": "2022-02-16T09:30:23.492230Z"
    },
    "papermill": {
     "duration": 1.322276,
     "end_time": "2022-02-16T09:30:23.492558",
     "exception": false,
     "start_time": "2022-02-16T09:30:22.170282",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = np.arange(20)\n",
    "fig = plt.figure()\n",
    "for e in [0.1, 0.2, 1.0, 5, 10]:\n",
    "    a = BetterAgent(concession_exponent=e)\n",
    "    y = [a._th(i, 20) for i in x]\n",
    "    plt.plot(x, y, label=f\"Concession Exponent: {e}\")\n",
    "    plt.xlabel(\"Step (Of 20)\"); plt.ylabel(\"Threshold $th$\")\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27af3848",
   "metadata": {
    "papermill": {
     "duration": 0.087218,
     "end_time": "2022-02-16T09:30:23.667719",
     "exception": false,
     "start_time": "2022-02-16T09:30:23.580501",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "You can see that the smaller the exponent the more *hard-headed* will the agent be. Setting the concession exponent to $0$ will recover the behavior of the `SimpleAgent` in offering but will make it insisting on an unrealistic best price when responding to partner offers (can you see why?) which is definitely a bad idea. Setting it to $\\inf$ will recover the behavior of `SimpleAgent` in responding to offers but will make its offers least favorable for itself in terms of price (can you see why?)\n",
    "\n",
    "Given this threshold function, we can now define `is_good_price` and `_find_good_price`:\n",
    "\n",
    "- ```_is_good_price``` simply compares the price given to it to the current threshold defined by multiplying ```th``` by the price range```mx - mn```\n",
    "   - When selling this is achieved by comparing the difference between the price and minimum price to the curren threshold:\n",
    "   \n",
    "    ```python\n",
    "    return (price - mn) >= th * (mx - mn)\n",
    "    ```\n",
    "    You can check that this will give the maximum unit price in the first step and gradually goes down to the minimum unit price in the last step (```n_steps - 1```)\n",
    "   - When buying we go the other way around (starting at minimum price and going up over time to the maximum price):\n",
    "   \n",
    "   ```python\n",
    "   return (mx - price) >= th * (mx - mn)\n",
    "   ```\n",
    "   \n",
    "- ```_find_good_price``` works in the same fashion but rather than checking the goodness of a price, it simply uses the threshold to generate a ```good-enough``` price:\n",
    "\n",
    "   ```python\n",
    "   if self._is_selling(ami):\n",
    "       return mn + th * (mx - mn)\n",
    "   else:\n",
    "       return mx - th * (mx - mn)\n",
    "   ```\n",
    "    \n",
    "#### Why did not this approach work\n",
    "\n",
    "As you may have noticed, `BetterAgent` is not relly better than `SimpleAgent`. why? The main reason is that price does not really matter that much in the settings for SCML 2023 OneShot because the price range is limited to only two consecutive values (e.g. (9, 10)) which increases the relative importance of avoiding penalties by matching demand and supply."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incoming-response",
   "metadata": {
    "papermill": {
     "duration": 0.087218,
     "end_time": "2022-02-16T09:30:23.667719",
     "exception": false,
     "start_time": "2022-02-16T09:30:23.580501",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Thinking about other negotiations\n",
    "\n",
    "So far, our agent behaved **indepdendently** in each negotiation without considering what is happening in the others (except when one of them completes changing the amount `secured`). A simple way to consider other negotiations is to use the prices offered in them to limit our concessions. The following agent implements this idea\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eligible-driver",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T09:30:23.865067Z",
     "iopub.status.busy": "2022-02-16T09:30:23.863928Z",
     "iopub.status.idle": "2022-02-16T09:30:31.990944Z",
     "shell.execute_reply": "2022-02-16T09:30:31.992167Z"
    },
    "papermill": {
     "duration": 8.237634,
     "end_time": "2022-02-16T09:30:31.992525",
     "exception": false,
     "start_time": "2022-02-16T09:30:23.754891",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AdaptiveAgent(BetterAgent):\n",
    "    \"\"\"Considers best price offers received when making its decisions\"\"\"\n",
    "\n",
    "    def before_step(self):\n",
    "        self._best_selling, self._best_buying = 0.0, float(\"inf\")\n",
    "                     \n",
    "    def respond(self, negotiator_id, state, source=''):\n",
    "        \"\"\"Save the best price received\"\"\"\n",
    "        offer = state.current_offer\n",
    "        response = super().respond(negotiator_id, state, source)\n",
    "        ami = self.get_nmi(negotiator_id)\n",
    "        if self._is_selling(ami):\n",
    "            self._best_selling = max(offer[UNIT_PRICE], self._best_selling)\n",
    "        else:\n",
    "            self._best_buying = min(offer[UNIT_PRICE], self._best_buying)\n",
    "        return response\n",
    "    \n",
    "    def _price_range(self, ami):\n",
    "        \"\"\"Limits the price by the best price received\"\"\"\n",
    "        mn, mx = super()._price_range(ami)\n",
    "        if self._is_selling(ami):\n",
    "            mn = max(mn, self._best_selling)\n",
    "        else:\n",
    "            mx = min(mx, self._best_buying)\n",
    "        return mn, mx\n",
    "\n",
    "world, ascores, tscores = try_agent(AdaptiveAgent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nutritional-cyprus",
   "metadata": {
    "papermill": {
     "duration": 0.083018,
     "end_time": "2022-02-16T09:30:32.158437",
     "exception": false,
     "start_time": "2022-02-16T09:30:32.075419",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's see how well did this agent behave:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "printable-occasion",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T09:30:32.413968Z",
     "iopub.status.busy": "2022-02-16T09:30:32.412061Z",
     "iopub.status.idle": "2022-02-16T09:30:32.423649Z",
     "shell.execute_reply": "2022-02-16T09:30:32.421316Z"
    },
    "papermill": {
     "duration": 0.142072,
     "end_time": "2022-02-16T09:30:32.423886",
     "exception": false,
     "start_time": "2022-02-16T09:30:32.281814",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "print_type_scores(tscores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alert-equipment",
   "metadata": {
    "papermill": {
     "duration": 0.081313,
     "end_time": "2022-02-16T09:30:32.587990",
     "exception": false,
     "start_time": "2022-02-16T09:30:32.506677",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Almost as good as `SimpleAgent`, at least in this simulation (we will make a more rigorous comparison later). One possiblity here is that the agent became too hard-headed again because now whenever it sees a good price on one negotiation, it insists on it for all the rest. This may not be a good idea sometimes as it may lead to more disagreements. In general *the agent must balance getting good prices with matching its input and output quantities*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "periodic-lightweight",
   "metadata": {
    "papermill": {
     "duration": 0.135832,
     "end_time": "2022-02-16T09:30:32.843638",
     "exception": false,
     "start_time": "2022-02-16T09:30:32.707806",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Learning over time\n",
    "\n",
    "Up until now, our simple agents did not change their behavior over simulation time. Whatever they do in one day depends only on information about what is happening on that day. This may not be optimal. For one, the agent may be able to learn about different partners over the simulation time. The following agent tries to do that in a *simplistic* manner by changing the limits of the price it is willing to accept based on accomulated statistics per agent.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "Note that this agent is not effective in 2024 because the price range is too small that it really does not matter much which price is agreed upon relative to the ability to avoid penalties by matching supply to demand.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greatest-siemens",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T09:30:33.075195Z",
     "iopub.status.busy": "2022-02-16T09:30:33.065745Z",
     "iopub.status.idle": "2022-02-16T09:30:45.721741Z",
     "shell.execute_reply": "2022-02-16T09:30:45.723209Z"
    },
    "papermill": {
     "duration": 12.784356,
     "end_time": "2022-02-16T09:30:45.723594",
     "exception": false,
     "start_time": "2022-02-16T09:30:32.939238",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LearningAgent(AdaptiveAgent):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *args,\n",
    "        acc_price_slack=float(\"inf\"),\n",
    "        step_price_slack=0.0,\n",
    "        opp_price_slack=0.0,\n",
    "        opp_acc_price_slack=0.2,\n",
    "        range_slack = 0.03,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self._acc_price_slack = acc_price_slack\n",
    "        self._step_price_slack = step_price_slack\n",
    "        self._opp_price_slack = opp_price_slack\n",
    "        self._opp_acc_price_slack = opp_acc_price_slack\n",
    "        self._range_slack = range_slack\n",
    "\n",
    "    def init(self):\n",
    "        \"\"\"Initialize the quantities and best prices received so far\"\"\"\n",
    "        super().init()\n",
    "        self._best_acc_selling, self._best_acc_buying = 0.0, float(\"inf\")\n",
    "        self._best_opp_selling = defaultdict(float)\n",
    "        self._best_opp_buying = defaultdict(lambda: float(\"inf\"))\n",
    "        self._best_opp_acc_selling = defaultdict(float)\n",
    "        self._best_opp_acc_buying = defaultdict(lambda: float(\"inf\"))        \n",
    "\n",
    "    def step(self):\n",
    "        \"\"\"Initialize the quantities and best prices received for next step\"\"\"\n",
    "        super().step()\n",
    "        self._best_opp_selling = defaultdict(float)\n",
    "        self._best_opp_buying = defaultdict(lambda: float(\"inf\"))\n",
    "\n",
    "    def on_negotiation_success(self, contract, mechanism):\n",
    "        \"\"\"Record sales/supplies secured\"\"\"\n",
    "        super().on_negotiation_success(contract, mechanism)\n",
    "\n",
    "        # update my current best price to use for limiting concession in other\n",
    "        # negotiations\n",
    "        up = contract.agreement[\"unit_price\"]\n",
    "        if self._is_selling(mechanism):\n",
    "            partner = contract.annotation[\"buyer\"]\n",
    "            self._best_acc_selling = max(up, self._best_acc_selling)\n",
    "            self._best_opp_acc_selling[partner] = max(up, self._best_opp_acc_selling[partner])\n",
    "        else:\n",
    "            partner = contract.annotation[\"seller\"]\n",
    "            self._best_acc_buying = min(up, self._best_acc_buying)\n",
    "            self._best_opp_acc_buying[partner] = min(up, self._best_opp_acc_buying[partner])\n",
    "\n",
    "    def respond(self, negotiator_id, state, source=''):\n",
    "        offer = state.current_offer\n",
    "        # find the quantity I still need and end negotiation if I need nothing more\n",
    "        response = super().respond(negotiator_id, state, source)\n",
    "        # update my current best price to use for limiting concession in other\n",
    "        # negotiations\n",
    "        ami = self.get_nmi(negotiator_id)\n",
    "        up = offer[UNIT_PRICE]\n",
    "        if self._is_selling(ami):\n",
    "            partner = ami.annotation[\"buyer\"]\n",
    "            self._best_opp_selling[partner] = max(up, self._best_selling)\n",
    "        else:\n",
    "            partner = ami.annotation[\"seller\"]\n",
    "            self._best_opp_buying[partner] = min(up, self._best_buying)\n",
    "        return response\n",
    "    \n",
    "    def _price_range(self, ami):\n",
    "        \"\"\"Limits the price by the best price received\"\"\"\n",
    "        mn = ami.issues[UNIT_PRICE].min_value\n",
    "        mx = ami.issues[UNIT_PRICE].max_value\n",
    "        if self._is_selling(ami):\n",
    "            partner = ami.annotation[\"buyer\"]\n",
    "            mn = min(mx * (1 - self._range_slack), max(\n",
    "                [mn]\n",
    "                + [\n",
    "                    p * (1 - slack)\n",
    "                    for p, slack in (\n",
    "                        (self._best_selling, self._step_price_slack),\n",
    "                        (self._best_acc_selling, self._acc_price_slack),\n",
    "                        (self._best_opp_selling[partner], self._opp_price_slack),\n",
    "                        (\n",
    "                            self._best_opp_acc_selling[partner],\n",
    "                            self._opp_acc_price_slack,\n",
    "                        ),\n",
    "                    )\n",
    "                ]\n",
    "            ))\n",
    "        else:\n",
    "            partner = ami.annotation[\"seller\"]\n",
    "            mx = max(mn * (1 + self._range_slack),  min(\n",
    "                [mx]\n",
    "                + [\n",
    "                    p * (1 + slack)\n",
    "                    for p, slack in (\n",
    "                        (self._best_buying, self._step_price_slack),\n",
    "                        (self._best_acc_buying, self._acc_price_slack),\n",
    "                        (self._best_opp_buying[partner], self._opp_price_slack),\n",
    "                        (\n",
    "                            self._best_opp_acc_buying[partner],\n",
    "                            self._opp_acc_price_slack,\n",
    "                        ),\n",
    "                    )\n",
    "                ]\n",
    "            ))\n",
    "        return mn, mx\n",
    "\n",
    "world, ascores, tscores = try_agent(LearningAgent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fancy-flashing",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T09:30:45.931823Z",
     "iopub.status.busy": "2022-02-16T09:30:45.928695Z",
     "iopub.status.idle": "2022-02-16T09:30:45.940358Z",
     "shell.execute_reply": "2022-02-16T09:30:45.934160Z"
    },
    "papermill": {
     "duration": 0.123276,
     "end_time": "2022-02-16T09:30:45.941002",
     "exception": false,
     "start_time": "2022-02-16T09:30:45.817726",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "print_type_scores(tscores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laughing-adoption",
   "metadata": {
    "papermill": {
     "duration": 0.094864,
     "end_time": "2022-02-16T09:30:46.133521",
     "exception": false,
     "start_time": "2022-02-16T09:30:46.038657",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The main idea of this agent is to limit the minimum price (for selling) and/or maximum price (for buying) based on events not only in this day but up until now. To do that, the agent accomulates best prices received in the same way `AdaptiveAgent` did in `init()` and `step()`. \n",
    "\n",
    "There are four simple differences between this agent and the previous one:\n",
    "\n",
    "1. It allows a controlled `slack` in price constraining. For example, if an agent of this type received a selling price of $10$, it will limit the minimum price considered *good-enough* in other negotiations to $10 \\times (1 - s)$ where $s$ is the slack term (e.g. setting $s=0.1$, leads to accepting offers at a price of $9$ as good enough). This may give the agent more flexibility and most importantly, this parameter **can be learned offline using any appropriate ML method**\n",
    "2. A best price **per partner** is kept in a `defaultdict()` that is initialized in `init` and updated in the same way the *partner independent* best prices are updated\n",
    "3. An `accumulated` statistic is kept (one for wll agents and one per agent) that is only initialized in `init()` and keeps being adjusted in `on_negotiation_success` without being reset in `step()`\n",
    "4. It keeps a `range_slack` to avoid setting too high minimum (or too low maximum) price. In effect, if the `range_slack` is $x$ then prices within the best $100x\\%$ of the best price are *always considered good enough*\n",
    "\n",
    "The main logic is in `_price_range()`. As usual, it starts by getting the price range from the `AMI`:\n",
    "\n",
    "```python\n",
    "mn = ami.issues[UNIT_PRICE].min_value\n",
    "mx = ami.issues[UNIT_PRICE].max_value\n",
    "```\n",
    "\n",
    "If the agent is a seller, it finds the partner ID:\n",
    "```python\n",
    "partner = ami.annotation[\"buyer\"]\n",
    "```\n",
    "\n",
    "Now that the partner is known, we can read the best offers received so far (in this day and over all days) for this partner. We can also retrieve the corresponding two partner-independent best prices with the corresponding slacks:\n",
    "\n",
    "```python\n",
    "(\n",
    "    (self._best_selling, self._step_price_slack),\n",
    "    (self._best_acc_selling, self._acc_price_slack),\n",
    "    (self._best_opp_selling[partner], self._opp_price_slack),\n",
    "    (\n",
    "        self._best_opp_acc_selling[partner],\n",
    "        self._opp_acc_price_slack,\n",
    "    ),\n",
    ")\n",
    "```\n",
    "\n",
    "For each price $p$ and slack value $slack$, we find the corrsponding price limit as:\n",
    "```python\n",
    "p * (1 - slack)\n",
    "```\n",
    "\n",
    "We then set the *good-enough* price limit to be the **maximum** of these four prices and the minimum price of the current negotiation (adjusted by the `range_slack` value). \n",
    "Finally we make sure that this is not too high by taking the **minimum** of this value and the maximum price of the current negotiation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a634c3",
   "metadata": {
    "papermill": {
     "duration": 0.200007,
     "end_time": "2022-02-16T09:31:01.399681",
     "exception": false,
     "start_time": "2022-02-16T09:31:01.199674",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Given that the utility function of the agent is defined in terms of a *complete set of contracts*, it is not trivial to define a utility function for each negotiation independent from the others (which is why this is an inherently concurrent negotiation world). It may be easier then to think of all negotiations in a synchronized manner. This means that the agent keeps collecting offers from its partners and when it has a *complete set*, it responds to all of them. Moreover, to start negotiations in which the agent finds itself the first propsoer, it needs to define a first proposal for each negotiation. Basing your agent on `SyncOneShotAgent` instead of `OneShotAgent` makes this easier. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesbian-dominant",
   "metadata": {
    "papermill": {
     "duration": 0.200007,
     "end_time": "2022-02-16T09:31:01.399681",
     "exception": false,
     "start_time": "2022-02-16T09:31:01.199674",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### OneShotSyncAgent\n",
    "\n",
    "One problem that plagued all of our agents so far is that they have to make decisions (`respond`, `propose`) about negotiations **on the spot**. This makes it difficult to consider **all other negotiations** while making decisions. \n",
    "\n",
    "Because the utility function is defined for **a complete set of negotiation agreements** and not for any single negotiation by itself, it makes sense to try to make decisions **centrally** by collecting offers from partners then responding to all of them at once. It is possible to do that by utilizing the response type ```ResponseType.WAIT``` supported by NegMAS but this entails a lot of house-keeping. \n",
    "\n",
    "To simplify this task, we provide another base class for agents that does all of this house keeping for you exposing a simple interface that **syncrhonizes** all negotiations (as much as allowed by the underlying platform). The main goal of this base agent is to allow the developer to think about *all negotiations together* but it has some important caveats which we will discuss later.\n",
    "Here is an example of writing the do-nothing agent in this form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mature-facing",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T09:31:01.645287Z",
     "iopub.status.busy": "2022-02-16T09:31:01.642359Z",
     "iopub.status.idle": "2022-02-16T09:31:05.625173Z",
     "shell.execute_reply": "2022-02-16T09:31:05.626008Z"
    },
    "papermill": {
     "duration": 4.113853,
     "end_time": "2022-02-16T09:31:05.626285",
     "exception": false,
     "start_time": "2022-02-16T09:31:01.512432",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from negmas import SAOResponse\n",
    "class MySyncOneShotDoNothing(OneShotSyncAgent):\n",
    "    \"\"\"My Agent that does nothing\"\"\"\n",
    "    def counter_all(self, offers, states):\n",
    "        \"\"\"Respond to a set of offers given the negotiation state of each.\"\"\"\n",
    "        return dict()\n",
    "    \n",
    "    def first_proposals(self):\n",
    "        \"\"\"Decide a first proposal on every negotiation. \n",
    "        Returning None for a negotiation means ending it.\"\"\"\n",
    "        return dict()\n",
    "    \n",
    "world, ascores, tscores = try_agent(MySyncOneShotDoNothing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moral-purse",
   "metadata": {
    "papermill": {
     "duration": 0.110793,
     "end_time": "2022-02-16T09:31:05.843238",
     "exception": false,
     "start_time": "2022-02-16T09:31:05.732445",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "As you can see, in this case, we need to override `counter_all` to counter offers received from *all* the partners and `first_proposals` to decide a first offer for *each* partner. \n",
    "\n",
    "Other than these two negotiation related callbacks, the agent receives an `init` call just after it joins the simulatin and a `step` call after each step. The agent is also informed about failure/success of negotiations through the `on_negotiation_success`/`on_negotiation_failure` callbacks. That is all. A one-shot agent needs to only think about what should it do to respond to each of these six callbacks. All of these callbacks except `counter_all` and `first_proposals` are optional."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspended-kenya",
   "metadata": {
    "papermill": {
     "duration": 0.104311,
     "end_time": "2022-02-16T09:31:06.051703",
     "exception": false,
     "start_time": "2022-02-16T09:31:05.947392",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### A not so-good SyncAgent\n",
    "\n",
    "The main advantage of using the `OneShotSyncAgent` is that you do not need to keep track of state variables (like `secured`, `_supplies` and `_sales` used earlier) and you have a common place to make your decisions about **all** negotiations at the same time. Here is a simple greedy agent using this approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handmade-foundation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T09:31:06.316833Z",
     "iopub.status.busy": "2022-02-16T09:31:06.303832Z",
     "iopub.status.idle": "2022-02-16T09:31:11.695643Z",
     "shell.execute_reply": "2022-02-16T09:31:11.696821Z"
    },
    "papermill": {
     "duration": 5.53954,
     "end_time": "2022-02-16T09:31:11.697135",
     "exception": false,
     "start_time": "2022-02-16T09:31:06.157595",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NaiveSyncAgent(OneShotSyncAgent, BetterAgent):\n",
    "    \"\"\"A greedy agent based on OneShotSyncAgent\"\"\"\n",
    "    \n",
    "    def __init__(self, *args, threshold=0.5, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self._threshold = threshold\n",
    "    \n",
    "    def before_step(self):\n",
    "        super().before_step()\n",
    "        self.ufun.find_limit(True)\n",
    "        self.ufun.find_limit(False)\n",
    "        \n",
    "    def first_proposals(self):\n",
    "        \"\"\"Decide a first proposal on every negotiation. \n",
    "        Returning None for a negotiation means ending it.\"\"\"\n",
    "        return  dict(zip(\n",
    "                self.negotiators.keys(), \n",
    "                (self.best_offer(_) for _ in self.negotiators.keys())\n",
    "        ))\n",
    "    \n",
    "    def counter_all(self, offers, states):\n",
    "        \"\"\"Respond to a set of offers given the negotiation state of each.\"\"\"\n",
    "        \n",
    "        # Initialize all responses by my best options\n",
    "        responses = {\n",
    "            k: SAOResponse(ResponseType.REJECT_OFFER, v) \n",
    "            for k, v in self.first_proposals().items()\n",
    "        }\n",
    "        \n",
    "        # find how much quantity do I still need\n",
    "        my_needs = self._needed()\n",
    "        \n",
    "        # Am I a seller?\n",
    "        is_selling = ( self._is_selling(self.get_nmi(_)) for _ in offers.keys() )\n",
    "        \n",
    "        # sort my offres by price (descendingly/ascendingly for a seller/buyer)\n",
    "        sorted_offers = sorted(\n",
    "            zip(offers.values(), is_selling), \n",
    "            key=lambda x: (- x[0][UNIT_PRICE]) if x[1] else x[0][UNIT_PRICE]\n",
    "        )\n",
    "        \n",
    "        # greedly choose offers until my needs are satsified\n",
    "        secured, outputs, chosen = 0, [], dict()\n",
    "        for i, k in enumerate(offers.keys()):\n",
    "            offer, is_output = sorted_offers[i]\n",
    "            secured += offer[QUANTITY]\n",
    "            if secured >= my_needs:\n",
    "                break\n",
    "            chosen[k] = offer\n",
    "            outputs.append(is_output)\n",
    "        \n",
    "        # calculate the utility of selected offers\n",
    "        u = self.ufun.from_offers(tuple(chosen.values()), tuple(outputs))\n",
    "        \n",
    "        # if the utility of selected offers is high enough, accept them\n",
    "        rng = self.ufun.max_utility - self.ufun.min_utility\n",
    "        threshold = self._threshold * rng + self.ufun.min_utility\n",
    "        if u >= threshold:\n",
    "            for k, v in chosen.items():\n",
    "                responses[k] = SAOResponse(ResponseType.ACCEPT_OFFER, None)                \n",
    "        return responses\n",
    "    \n",
    "world, ascores, tscores = try_agent(NaiveSyncAgent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enormous-islam",
   "metadata": {
    "papermill": {
     "duration": 0.110052,
     "end_time": "2022-02-16T09:31:11.912749",
     "exception": false,
     "start_time": "2022-02-16T09:31:11.802697",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This agent shows a case of parameterizing your agent so that it can be tested with different hyper-parameters. You do that by passing whatever parameters you like as keyword arguments to the constctor:\n",
    "\n",
    "```python\n",
    "def __init__(self, *args, threshold=0.3, **kwargs):\n",
    "    super().__init__(*args, **kwargs)\n",
    "    self._threshold = threshold\n",
    "```\n",
    "\n",
    "The one paramter we have is a threshold of utility relative to the maximum possile utility that we are willing to accept.\n",
    "\n",
    "This agent also shows a case in which we use the built-in utility function implemented by the system (see [Section 2.3 of the game description](http://www.yasserm.com/scml/scml2021oneshot.pdf)). This ufun is accessible as `ufun`. By default the ufun will return the profit in dollars for a given set of negotiation outcomes, offers, agreements, or contracts. Note that the ufun assumes that what it is given *is the complete set of agreements and no others will be added to them later*. This value may be positive or negative (loss). In some cases you need to get the utility value normalized to a range between zero and one. This agent will do that. To do this normalization, we need to know the value of maximum and minimum utilities. You can of course solve the corresponding optimziation problem but we did that for you. All you need is call `find_limit` and pass it a boolean (`True` for calculating the highest possible utility and `False` for calculating the lowest possible utility). To avoid doing this calculation repeatedly, you should store the results in `ufun.best` or `ufun.worst` for highest and lowest utility. After that, you can access the maximum possible utility as `max_utility` and minimum possible utility as `min_utility`. We do that in the `before_step()` method (called at the beginning of every day):\n",
    "\n",
    "```python\n",
    " def before_step(self):\n",
    "    super().init()\n",
    "    self.ufun.find_limit(True)\n",
    "    self.ufun.find_limit(False)\n",
    "```\n",
    "\n",
    "After this call, we can access `maximum_utility`, `minimum_utility`, `best`, `worst` members of the ufun. As explained earlier, `best` and `worst` give extra information about the conditions for achieving maximum and minimum utility.\n",
    "\n",
    "We need to implement two methods: `first_proposals` (to generate a good first proposal for each negotiation) and `counter_all` (for countering a set of offers). We inherit from `SimpleAgent` in order to get access to `best_offer` and `_is_selling` methods (we could have repeated them here again of course. Note that, because of the way inheritence works in python, we must inherit from `OneShotSyncAgent` before `SimpleAgent`.\n",
    "\n",
    "The first set of proposals in `first_proposals` is simply the `best_offer` for each negotiation which is calculated using this generator expression:\n",
    "```python\n",
    "(self.best_offer(_) for _ in self.negotiators.keys())\n",
    "```\n",
    "\n",
    "\n",
    "Almost all the code now resides in the `counter_all` method. We will go over it here:\n",
    "\n",
    "- We start by initializing our response by the best offer for each negotiation using `first_proposals` and calculating our needs using `_needed`\n",
    "```python\n",
    "responses = {\n",
    "    k: SAOResponse(ResponseType.REJECT_OFFER, _) \n",
    "    for k, v in self.first_proposals().items()\n",
    "}\n",
    "my_needs = self._needed(None)\n",
    "```\n",
    "\n",
    "- We then sort the offers so that earlier offers have *better* prices for us. For sell offers, this means descendingly and for buy offers ascendingly.\n",
    "```python\n",
    "is_selling = ( self._is_selling(self.get_nmi(_)) for _ in offers.keys() )\n",
    "sorted_offers = sorted(\n",
    "    zip(offers.values(), is_selling), \n",
    "    key=lambda x: (- x[0][UNIT_PRICE]) if x[1] else x[0][UNIT_PRICE]\n",
    ")\n",
    "```\n",
    "- We *greedily* find a set of offers that satisfy all our needs (or as much as possible from them). \n",
    "```python\n",
    "secured, outputs, chosen = 0, [], dict()\n",
    "for i, k in enumerate(offers.keys()):\n",
    "    offer, is_output = sorted_offers[i]\n",
    "    secured += offer[QUANTITY]\n",
    "    if secured >= my_needs:\n",
    "        break\n",
    "    chosen[k] = offer\n",
    "    outputs.append(is_output)\n",
    "```\n",
    "- Finally, we calculate the utility of accepting these *and only these* offers and accept the chosen offers if they provide 70% of the maximum possible utility. Otherwise, we reject all offers sending the default `best_offer` value back.\n",
    "```python\n",
    "u = self.ufun.from_offers(tuple(chosen.values()), tuple(outputs))\n",
    "rng = self.ufun.max_utility - self.ufun.min_utility\n",
    "threshold = self._threshold * rng + self.ufun.min_utility\n",
    "if u >= threshold:\n",
    "    for k, v in chosen.items():\n",
    "        responses[k] = SAOResponse(ResponseType.ACCEPT_OFFER, None)\n",
    "return responses\n",
    "```\n",
    "\n",
    "Let's see how did it do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "included-peripheral",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T09:31:12.176407Z",
     "iopub.status.busy": "2022-02-16T09:31:12.161291Z",
     "iopub.status.idle": "2022-02-16T09:31:12.180315Z",
     "shell.execute_reply": "2022-02-16T09:31:12.157068Z"
    },
    "papermill": {
     "duration": 0.1478,
     "end_time": "2022-02-16T09:31:12.180893",
     "exception": false,
     "start_time": "2022-02-16T09:31:12.033093",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print_type_scores(tscores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec5c2ec",
   "metadata": {
    "papermill": {
     "duration": 0.101838,
     "end_time": "2022-02-16T09:31:12.524791",
     "exception": false,
     "start_time": "2022-02-16T09:31:12.422953",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This base-class simplifies the job of the agent developer by providing a single function (`counter_all`) in which to handle all offers it receive (most of the time, remember that sometimes you will receive a subset of the offers in the call). In principle the agent can then decide to accept a few of these offers and keep negotiating. \n",
    "\n",
    "The problem with this agent is that it defines a **good offer** independently for each negotiation which defeats the purpose of having the chance to decide centrally what to do for all negotiations. That is made even less effective by the fact that in SCML 2023, price does not matter that much. In the following section, we design a very simple alternative that tries to resolve this issue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a5168e",
   "metadata": {
    "papermill": {
     "duration": 0.101838,
     "end_time": "2022-02-16T09:31:12.524791",
     "exception": false,
     "start_time": "2022-02-16T09:31:12.422953",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### A better SyncAgent\n",
    "\n",
    "We start by defining a simple helper function that distributes a given quantity $q$ over $n$ partners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polished-windsor",
   "metadata": {
    "papermill": {
     "duration": 0.138304,
     "end_time": "2022-02-16T09:39:07.021727",
     "exception": false,
     "start_time": "2022-02-16T09:39:06.883423",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def distribute(q: int, n: int) -> list[int]:\n",
    "    \"\"\"Distributes n values over m bins with at least one item per bin assuming q > n\"\"\"\n",
    "    from numpy.random import choice\n",
    "    from collections import Counter\n",
    "    if q < n:\n",
    "        lst = [0] * (n - q) + [1] * q\n",
    "        random.shuffle(lst)\n",
    "        return lst\n",
    "        \n",
    "    if q == n:\n",
    "        return [1] * n\n",
    "    r = Counter(choice(n, q - n))    \n",
    "    return [r.get(_, 0) + 1 for _ in range(n)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b40ef7",
   "metadata": {},
   "source": [
    "Here are few examples of how it would distribute $10$ units over $4$ partners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fc4ff5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[distribute(10, 4) for _ in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9c7bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "[distribute(2, 4) for _ in range(5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b38abe9",
   "metadata": {},
   "source": [
    "We will also need a helper function to find all subsets of a given set (powerset):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb739bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain, combinations\n",
    "\n",
    "def powerset(iterable):\n",
    "    s = list(iterable)\n",
    "    return chain.from_iterable(combinations(s, r) for r in range(len(s)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fbdc6b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class SyncRandomAgent(OneShotSyncAgent):\n",
    "    \"\"\"An agent that distributes its needs over its partners randomly.\"\"\"\n",
    "\n",
    "    def __init__(self, *args, threshold=0.95, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self._threshold = threshold\n",
    "\n",
    "    def distribute_needs(self) -> dict[str, int]:\n",
    "        \"\"\"Distributes my needs randomly over all my partners\"\"\"\n",
    "\n",
    "        dist = dict()\n",
    "        for needs, all_partners in [\n",
    "            (self.awi.needed_supplies, self.awi.my_suppliers),\n",
    "            (self.awi.needed_sales, self.awi.my_consumers),\n",
    "        ]:\n",
    "            # find suppliers and consumers still negotiating with me\n",
    "            partner_ids = [_ for _ in all_partners if _ in self.negotiators.keys()]\n",
    "            partners = len(partner_ids)            \n",
    "\n",
    "            # if I need nothing, end all negotiations\n",
    "            if needs <= 0:\n",
    "                dist.update(dict(zip(partner_ids, [0] * partners)))\n",
    "                continue\n",
    "\n",
    "            # distribute my needs over my (remaining) partners.\n",
    "            dist.update(dict(zip(partner_ids, distribute(needs, partners))))\n",
    "        return dist\n",
    "\n",
    "    def first_proposals(self):\n",
    "        # just randomly distribute my needs over my partners (with best price for me).\n",
    "        s, p = self._step_and_price(best_price=True)\n",
    "        distribution = self.distribute_needs()    \n",
    "        d = {k: (q, s, p) if q > 0 else None for k, q in distribution.items()}\n",
    "        return d\n",
    "\n",
    "    def counter_all(self, offers, states):\n",
    "        response = dict()\n",
    "        # process for sales and supplies independently\n",
    "        for needs, all_partners, issues in [\n",
    "            (\n",
    "                self.awi.needed_supplies,\n",
    "                self.awi.my_suppliers,\n",
    "                self.awi.current_input_issues,\n",
    "            ),\n",
    "            (\n",
    "                self.awi.needed_sales,\n",
    "                self.awi.my_consumers,\n",
    "                self.awi.current_output_issues,\n",
    "            ),\n",
    "        ]:\n",
    "            # get a random price\n",
    "            price = issues[UNIT_PRICE].rand()\n",
    "            # find active partners\n",
    "            partners = {_ for _ in all_partners if _ in offers.keys()}\n",
    "\n",
    "            # find the set of partners that gave me the best offer set\n",
    "            # (i.e. total quantity nearest to my needs)\n",
    "            plist = list(powerset(partners))\n",
    "            best_diff, best_indx = float(\"inf\"), -1\n",
    "            for i, partner_ids in enumerate(plist):\n",
    "                others = partners.difference(partner_ids)\n",
    "                offered = sum(offers[p][QUANTITY] for p in partner_ids)\n",
    "                diff = abs(offered - needs)\n",
    "                if diff < best_diff:\n",
    "                    best_diff, best_indx = diff, i\n",
    "                if diff == 0:\n",
    "                    break\n",
    "\n",
    "            # If the best combination of offers is good enough, accept them and end all\n",
    "            # other negotiations\n",
    "            if best_diff <= self._threshold:\n",
    "                partner_ids = plist[best_indx]\n",
    "                others = list(partners.difference(partner_ids))\n",
    "                response.update({\n",
    "                    k: SAOResponse(ResponseType.ACCEPT_OFFER, offers[k]) for k in partner_ids\n",
    "                } | {k: SAOResponse(ResponseType.END_NEGOTIATION, None) for k in others})\n",
    "                continue\n",
    "\n",
    "            # If I still do not have a good enough offer, distribute my current needs\n",
    "            # randomly over my partners.\n",
    "            distribution = self.distribute_needs()\n",
    "            response.update(\n",
    "                {\n",
    "                    k: SAOResponse(ResponseType.END_NEGOTIATION, None)\n",
    "                    if q == 0\n",
    "                    else SAOResponse(\n",
    "                        ResponseType.REJECT_OFFER, (q, self.awi.current_step, price)\n",
    "                    )\n",
    "                    for k, q in distribution.items()\n",
    "                }\n",
    "            )        \n",
    "        return response\n",
    "\n",
    "    def _step_and_price(self, best_price=False):\n",
    "        \"\"\"Returns current step and a random (or max) price\"\"\"\n",
    "        s = self.awi.current_step\n",
    "        seller = self.awi.is_first_level\n",
    "        issues = (\n",
    "            self.awi.current_output_issues if seller else self.awi.current_input_issues\n",
    "        )\n",
    "        pmin = issues[UNIT_PRICE].min_value\n",
    "        pmax = issues[UNIT_PRICE].max_value\n",
    "        if best_price:\n",
    "            return s, pmax if seller else pmin\n",
    "        return s, random.randint(pmin, pmax)\n",
    "world, ascores, tscores = try_agent(SyncRandomAgent)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7acd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_type_scores(tscores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f3e58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_type_scores(tscores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mathematical-prisoner",
   "metadata": {
    "papermill": {
     "duration": 0.101838,
     "end_time": "2022-02-16T09:31:12.524791",
     "exception": false,
     "start_time": "2022-02-16T09:31:12.422953",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This is the highest score we got so far even though that agent is not that intelligent in its decision making. Let's check it in details:\n",
    "\n",
    "The main idea is to generate offers that will (assuming all accepted) give us all the quantity we need (to buy/sell). Moreover, we accept a set of offers if the total quantity they provide is within some small margin from the quantity we need.\n",
    "\n",
    "\n",
    "We have a helper method to calculate the quantity we need at any time which simply subtracts the secured quantity from our total exogenous contract quantities:\n",
    "\n",
    "```python\n",
    "def _needs(self):\n",
    "    if self.awi.is_first_level:\n",
    "        return self.awi.needed_sales\n",
    "    return self.awi.needed_supplies\n",
    "``` \n",
    "\n",
    "Another helper function (`_step_and_price`) is defined to return the current step and one of the two prices in the agenda:\n",
    "\n",
    "```python\n",
    "def _step_and_price(self, best_price = False):\n",
    "    \"\"\"Returns current step and a random (or max) price\"\"\"\n",
    "    s = self.awi.current_step\n",
    "    seller = self.awi.is_first_level\n",
    "    issues = (\n",
    "        self.awi.current_output_issues \n",
    "        if seller else \n",
    "        self.awi.current_input_issues\n",
    "    )\n",
    "    pmin = issues[UNIT_PRICE].min_value\n",
    "    pmax = issues[UNIT_PRICE].max_value\n",
    "    if best_price:\n",
    "        return s, pmax\n",
    "    return s, random.randint(pmin, pmax)\n",
    "```\n",
    "\n",
    "The core computation of the agent is implemented in the `distribute_needs()` method which is responsible of calculating a quantity for each partner (notice that price is completely ignored here).\n",
    "\n",
    "Firstly, we find our partner and our needs and if we do not need anything, we simply return $0$ for all partners:\n",
    "\n",
    "```python\n",
    "  partner_ids = list(self.negotiators.keys())\n",
    "  partners = len(partner_ids)\n",
    "  needs = self._needs()\n",
    "  if needs <= 0:\n",
    "      return dict(zip(partner_ids, [0] * partners))\n",
    "```\n",
    "\n",
    "If our needs cannot be distributed over all partners, we select some of our partners randomly and return $0$ for them (as we will see, this will end the negotiation with these partners):\n",
    "\n",
    "```python\n",
    "if needs < partners:\n",
    "    to_end = random.sample(partner_ids, (partners - needs))\n",
    "    response = dict(zip(to_end, [0] * len(to_end)))\n",
    "    partner_ids = [_ for _ in partner_ids if _ not in to_end]\n",
    "    partners = len(partner_ids)\n",
    "```\n",
    "\n",
    "Finally, we simply distribute our needs over the remaining partners uniformly:\n",
    "\n",
    "```python\n",
    "response.update(dict(zip(partner_ids, distribute(needs, partners))))\n",
    "```\n",
    "\n",
    "Now we can move the main part of the agent which consists of the two abstract method implementations (`first_proposals` and `counter_all`).\n",
    "\n",
    "#### First set of offers\n",
    "\n",
    "The first set of proposals from the agent use the best price and will distribute the total quantity needed randomly between all partners:\n",
    "```python\n",
    "s, p = self._step_and_price(best_price=True)\n",
    "distribution = self.distribute_needs()    \n",
    "```\n",
    "\n",
    "We then just return the quantity for each partner or `None` to end the negotiation if the quantity was $0$\n",
    "```python\n",
    "return dict((k, (q, s, p) if q > 0 else None)  for k, q in distribution.items())\n",
    "```\n",
    "\n",
    "#### Countering offers\n",
    "When we receive some offers (in `counter_all`) we start by finding the subset of them (together) that best satisfy our needs up to a predefined threshold (defaulting to zero)\n",
    "\n",
    "```python\n",
    "plist = list(powerset(partners))\n",
    "best_diff, best_indx = float(\"inf\"), -1\n",
    "for i, partner_ids in enumerate(plist):\n",
    "    others = partners.difference(partner_ids)\n",
    "    offered = sum(offers[p][QUANTITY] for p in partner_ids)\n",
    "    diff = abs(offered - needs)\n",
    "    if diff < best_diff:\n",
    "        best_diff, best_indx = diff, i\n",
    "    if diff == 0:\n",
    "        break\n",
    "```\n",
    "\n",
    "If the best subset satisfies our needs up to a threshold (set as zero by default), we simply accept all of them ending all other negotiations:\n",
    "\n",
    "```python\n",
    "if best_diff <= self._threshold:\n",
    "    partner_ids = plist[best_indx]\n",
    "    others = list(partners.difference(partner_ids))\n",
    "    return {\n",
    "        k: SAOResponse(ResponseType.ACCEPT_OFFER, None) for k in partner_ids\n",
    "    } | {k: SAOResponse(ResponseType.END_NEGOTIATION, None) for k in others}\n",
    "```\n",
    "\n",
    "*Note that we could slightly improve that by only rejecting the remaining offers and offering whatever we still need to buy/sell to them when the threshold is nonezero and the best subset has a total quantity less than our needs. This may improve our results slightly but will complicate the code so we do not pursue it in this tutorial.*\n",
    "\n",
    "If the best subset does not satisfy our needs up to the predefined threshold, we simply ignore all offers and generate a new random offer for our partners:\n",
    "\n",
    "```python\n",
    "distribution = self.distribute_needs()\n",
    "return {\n",
    "    k: SAOResponse(ResponseType.END_NEGOTIATION, None)\n",
    "    if q == 0\n",
    "    else SAOResponse(ResponseType.REJECT_OFFER, (q, s, p))\n",
    "    for k, q in distribution.items()\n",
    "}\n",
    "```    \n",
    "\n",
    "*Note that we simply end the negotiation with some partners (selected randomly) if our needs are less than the number of our partners (see `distribute_needs()`.*\n",
    "\n",
    "#### Possible Improvements\n",
    "\n",
    "There are obvious ways to improve this agent:\n",
    "\n",
    "1. When countering offers, we should take into account the history of negotiation with each partner (in this round and previously) to make a more meaningful distribution of quantities over partners. Currently this is just random. We should also consider the probability that our offers will be accepted when deciding how to distribute the quantity we still need over our partners.\n",
    "1. Choosing which negotiators to end the negotiation with when we need a small quantity to buy/sell, is currently random. We could try to find a way to only end negotiation with negotiators least likely to provide us with our remaining needs.\n",
    "1. As indicated earlier, we should not just end the negotiation with all unselected partners when we accept some subset of the offers if the threshold was nonzero and the total quantity we are accepting is not enough to satisfy our needs.\n",
    "1. We should take the number of rounds remiaining in the negotiation when deciding whether to accept a subset of offers (e.g. have a higher threshold near the end of the negotiation), and when deciding what quantities to distribute over our partners (e.g. offer more than what we need near the end of the negotiation under the assumption that only some of them will be accepted).\n",
    "1. May be consider prices more when approaching our total needs.\n",
    "\n",
    "\n",
    "In many cases, it may be possible to secure all of the agent's needs (i.e. supplies or sales) using a **single** contract with one of its partners. In such cases, the agent can think about the negotiations it is engaged in as a **competetive negotiation** not very dissimilar from an auction that also allows it to offer. This can lead to a further simplification, the agent can be designed to get **at most one agreement** from the set of negotiation and end all the rest once this is achieved. This is what the `SingleAgreementOneShotAgent` does."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "super-gambling",
   "metadata": {
    "papermill": {
     "duration": 0.107324,
     "end_time": "2022-02-16T09:31:12.738186",
     "exception": false,
     "start_time": "2022-02-16T09:31:12.630862",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Limiting the agent to a single agreement \n",
    "You can limit your agent to have no more than one agreement every time step by basing your agent on `SingleAgreementOneShotAgent`.\n",
    "\n",
    "This controller manages a set of negotiations from which only a single one\n",
    "-- at most -- is likely to result in an agreement. To guarentee a single agreement, pass ```strict=True```.\n",
    "\n",
    "The general algorithm for this agent is something like this:\n",
    "\n",
    "- Receive offers from all partners.\n",
    "- Find the best offer among them by calling the abstract `best_offer`\n",
    "  method.\n",
    "- Check if this best offer is acceptable using the abstract `is_acceptable`\n",
    "  method.\n",
    "\n",
    "    - If the best offer is acceptable, accept it and end all other negotiations.\n",
    "    - If the best offer is still not acceptable, then all offers are rejected\n",
    "      and with the partner who sent it receiving the result of `best_outcome`\n",
    "      while the rest of the partners receive the result of `make_outcome`.\n",
    "\n",
    "- The default behavior of `best_outcome` is to return the outcome with\n",
    "  maximum utility.\n",
    "- The default behavior of `make_outcome` is to return the best offer\n",
    "  received in this round if it is valid for the respective negotiation\n",
    "  and the result of `best_outcome` otherwise.\n",
    "  \n",
    "To use this agent, you need to implement three methods:\n",
    "\n",
    "- `is_acceptable` decides whether an offer is now acceptable. For this simple agent, we accept an offer if it provides us with a decreasing fraction of the maximum utility attainable. Notice that, because we set `mn` to `min_utility`, the agent may actually accept offers with negative utility!! This can easily be fixed by setting `mn` to zero but will lead to much less trade.\n",
    "```python\n",
    "mx, mn = self.ufun.max_utility , self.ufun.min_utility\n",
    "u = (self.ufun(offer) - mn) / (mx - mn) \n",
    "return  u >= (1-state.relative_time)\n",
    "```\n",
    "- `best_offer` finds the best offer among a set of offers. Here we simply compare their utility\n",
    "```python\n",
    "ufuns = [(self.ufun(_), i) for i, _ in enumerate(offers.values())]\n",
    "keys = list(offers.keys())\n",
    "return keys[max(ufuns)[1]]\n",
    "```\n",
    "- `is_better` which compares two offers from the same negotiator. We simply compare their utility value:\n",
    "```python\n",
    "return self.ufun(a) > self.ufun(b)\n",
    "```\n",
    "\n",
    "Here is the full agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acoustic-carolina",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T09:31:12.993927Z",
     "iopub.status.busy": "2022-02-16T09:31:12.989383Z",
     "iopub.status.idle": "2022-02-16T09:31:20.684135Z",
     "shell.execute_reply": "2022-02-16T09:31:20.685347Z"
    },
    "papermill": {
     "duration": 7.834888,
     "end_time": "2022-02-16T09:31:20.685609",
     "exception": false,
     "start_time": "2022-02-16T09:31:12.850721",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SimpleSingleAgreementAgent(OneShotSingleAgreementAgent):\n",
    "    \"\"\"A greedy agent based on OneShotSingleAgreementAgent\"\"\"\n",
    "    \n",
    "    def before_step(self):\n",
    "        self.ufun.find_limit(True) # finds highest utility\n",
    "        self.ufun.find_limit(False) # finds lowest utility\n",
    "    \n",
    "    def is_acceptable(self, offer, source, state) -> bool:        \n",
    "        mx, mn = self.ufun.max_utility , self.ufun.min_utility\n",
    "        u = (self.ufun(offer) - mn) / (mx - mn) \n",
    "        return  u >= (1-state.relative_time)\n",
    "\n",
    "    def best_offer(self, offers):\n",
    "        ufuns = [(self.ufun(_), i) \n",
    "                 for i, _ in enumerate(offers.values())]\n",
    "        keys = list(offers.keys())\n",
    "        return keys[max(ufuns)[1]]\n",
    "\n",
    "    def is_better(self, a, b, negotiator, state):\n",
    "        return self.ufun(a) > self.ufun(b)\n",
    "\n",
    "world, ascors, tscores = try_agent(SimpleSingleAgreementAgent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alone-ebony",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T09:31:20.919989Z",
     "iopub.status.busy": "2022-02-16T09:31:20.918353Z",
     "iopub.status.idle": "2022-02-16T09:31:20.927549Z",
     "shell.execute_reply": "2022-02-16T09:31:20.926666Z"
    },
    "papermill": {
     "duration": 0.12666,
     "end_time": "2022-02-16T09:31:20.928057",
     "exception": false,
     "start_time": "2022-02-16T09:31:20.801397",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print_type_scores(tscores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enclosed-broadcast",
   "metadata": {
    "papermill": {
     "duration": 0.112265,
     "end_time": "2022-02-16T09:31:21.154639",
     "exception": false,
     "start_time": "2022-02-16T09:31:21.042374",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Using Independent Negotiators\n",
    "\n",
    "The SCML game is at its core a concurrent negotiation problem. That is why the default `OneShotAgent` receives all calls from the simulator and responds to them centerally. Nevertheless, you man want to structure your agent in a different way. Let's assume that you found a way to create *independent utility functions* to be used with each of your partners. Assuming that your ufuns can summarize what is expected to happen in all other negotiations, you can use the `OneShotIndNegotiatorsAgent` to build an agent that delegates all of its control to independent negotiators that use these per-partner utility functions. \n",
    "\n",
    "In this case, you only need to implement `generate_ufuns()` which is responsible of creating these **independent per-partner utility functions** every day. You need also to specify the negotiator to be used with each partner. By default the agent will create an `AspirationNegotiator` for each of your partners. You can override this default behavior by passing custom `default_negotiator_type`/`default_negotiator_params` to the agent constructor. If you need even more control, you can override `generate_negotiator()` to create a custom negotiator object per partner every day. \n",
    "\n",
    "This is an example agent that uses this approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certified-edition",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T09:31:21.605157Z",
     "iopub.status.busy": "2022-02-16T09:31:21.602967Z",
     "iopub.status.idle": "2022-02-16T09:32:00.961520Z",
     "shell.execute_reply": "2022-02-16T09:32:00.960710Z"
    },
    "papermill": {
     "duration": 39.519634,
     "end_time": "2022-02-16T09:32:00.961744",
     "exception": false,
     "start_time": "2022-02-16T09:31:21.442110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scml.oneshot import OneShotIndNegotiatorsAgent\n",
    "\n",
    "class AssumeOthersFailIndNeg(OneShotIndNegotiatorsAgent):\n",
    "    def generate_ufuns(self):\n",
    "        return defaultdict(lambda: self.ufun)\n",
    "world, ascors, tscores = try_agent(AssumeOthersFailIndNeg)\n",
    "print_type_scores(tscores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "victorian-reputation",
   "metadata": {
    "papermill": {
     "duration": 0.118037,
     "end_time": "2022-02-16T09:32:01.193781",
     "exception": false,
     "start_time": "2022-02-16T09:32:01.075744",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This agent simply uses its **central** ufun for each negotiator. This is not a very good strategy because each negotiator is now assuming that *all other negotiations will fail*. Can you see why?\n",
    "\n",
    "Let's make a slightly more meaningful agent. This time, the utility function used per partner will try to find a favorable price but will not care about quantity. This is obviously not a good strategy either because the agent may over-contract. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "junior-telling",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T09:32:01.697008Z",
     "iopub.status.busy": "2022-02-16T09:32:01.695260Z",
     "iopub.status.idle": "2022-02-16T09:32:11.838562Z",
     "shell.execute_reply": "2022-02-16T09:32:11.839508Z"
    },
    "papermill": {
     "duration": 10.472074,
     "end_time": "2022-02-16T09:32:11.839768",
     "exception": false,
     "start_time": "2022-02-16T09:32:01.367694",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from negmas.preferences import LinearAdditiveUtilityFunction, LinearUtilityFunction\n",
    "from negmas.preferences.value_fun import AffineFun, IdentityFun\n",
    "\n",
    "class GreedyIndNeg(OneShotIndNegotiatorsAgent):\n",
    "    def generate_ufuns(self):\n",
    "        d = dict()\n",
    "        # generate ufuns that prefer higher prices when selling\n",
    "        for partner_id in itertools.chain(self.awi.my_consumers, self.awi.my_suppliers):\n",
    "            issues = self.awi.current_output_issues\n",
    "            if self.awi.is_system(partner_id):\n",
    "                continue\n",
    "            d[partner_id] = LinearUtilityFunction(\n",
    "                weights=dict(quantity=1.0, time=0.0, unit_price=0.0),\n",
    "                issues=issues,\n",
    "                reserved_value=0.0,\n",
    "            )\n",
    "        return d\n",
    "\n",
    "world, ascors, tscores = try_agent(GreedyIndNeg)\n",
    "\n",
    "print_type_scores(tscores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integrated-dakota",
   "metadata": {
    "papermill": {
     "duration": 0.159221,
     "end_time": "2022-02-16T09:32:12.130970",
     "exception": false,
     "start_time": "2022-02-16T09:32:11.971749",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Using A Negotiator from the Genius Platform\n",
    "\n",
    "One advantage of this type of agents is that it allows you to use almost any [Genius](http://ii.tudelft.nl/genius/) including most winners of past ANAC competitions as your negotiator once you could come up with a good utility function per partner (not an easy task at all).\n",
    "\n",
    "To be able to use these genius negotiators, you need to have some extra constraints on your utility function:\n",
    "\n",
    "- All ufuns are of the type `LinearAdditiveUtilityFunction` or `LinearUtilityFunction`.\n",
    "- All ufuns are normalized with a maximum value of 1.0. You can\n",
    "  use `normalize_ufuns=True` to gruarantee that.\n",
    "- All ufuns have a finite reserved value and at least one outcome is\n",
    "  above it. You can guarantee that by using `set_reservation=True`.\n",
    "- All weights of the utility function must be between\n",
    "  zero and one and the weights must sum to one.\n",
    "\n",
    "\n",
    "If all of these conditions are satisfied, you can use a Genius based negotiator by following these steps:\n",
    "\n",
    "1. Install the negmas-genius bridge by running on the terminal (this will download the bridge):\n",
    "   ```bash\n",
    "   negmas genius-setup\n",
    "   ```\n",
    "2. Run a world or a tournament as usual.\n",
    "\n",
    "You need to have `java` installed (15.0 or later). *Please note that we do not officially support any Genius agents for SCML. Moreover, due to the way the bridge is implemented, these agents will tend to be much slower than negotiators developed directly in python and may suffer from more timeouts as a result. It may be a good idea to reimplement whatever strategy you prefer in python to guarantee stable performance*.\n",
    "\n",
    "If your Genius negotiation did not start, you can explicitly run the negmas-genius bridge using one of the following two commands:\n",
    "\n",
    "- Start the negmas-genius bridbe by running on the terminal:\n",
    "   ```bash\n",
    "   negmas genius\n",
    "   ```\n",
    "- In some cases, the aforementioned command may not work correctly (specially on windows), you can replace it with:\n",
    "   ```bash\n",
    "   java -jar $HOME/nemgas/files/geniusbridge.jar\n",
    "   ```\n",
    "\n",
    "The only change you need to do in your code is to choose an appropriate `GeniusNegotiator`. Note that not all agents in the genius platform will work correctly. Here is an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessory-element",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T09:32:12.580120Z",
     "iopub.status.busy": "2022-02-16T09:32:12.573689Z",
     "iopub.status.idle": "2022-02-16T09:33:11.161642Z",
     "shell.execute_reply": "2022-02-16T09:33:11.159133Z"
    },
    "papermill": {
     "duration": 58.849036,
     "end_time": "2022-02-16T09:33:11.163604",
     "exception": false,
     "start_time": "2022-02-16T09:32:12.314568",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import a specific agent from the Genius platform\n",
    "from negmas.genius.gnegotiators import Atlas3\n",
    "\n",
    "class GeniusIndNeg(GreedyIndNeg):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        kwargs[\"default_negotiator_type\"] = Atlas3\n",
    "        kwargs[\"normalize_ufuns\"] = True\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "world, ascors, tscores = try_agent(GeniusIndNeg)\n",
    "print_type_scores(tscores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broke-interaction",
   "metadata": {
    "papermill": {
     "duration": 0.169436,
     "end_time": "2022-02-16T09:30:46.425243",
     "exception": false,
     "start_time": "2022-02-16T09:30:46.255807",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### More General Simple Agent (advanced)\n",
    "\n",
    "<div style=\"color: red;\">This section is not necessary for SCML-OneShot 2023 competition because all worlds in the competition will have exactly 2 processes (3 products). It is here for readers interested in making their agents future-proof.</div>\n",
    "\n",
    "One issue that the `SimpleAgent` had was that it assumed that it is either in the first level of the production chain or in the last level. To make an agent that works anywhere, we need just minor modifications:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-harrison",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T09:30:46.697596Z",
     "iopub.status.busy": "2022-02-16T09:30:46.695615Z",
     "iopub.status.idle": "2022-02-16T09:30:46.699182Z",
     "shell.execute_reply": "2022-02-16T09:30:46.698436Z"
    },
    "papermill": {
     "duration": 0.120057,
     "end_time": "2022-02-16T09:30:46.699402",
     "exception": false,
     "start_time": "2022-02-16T09:30:46.579345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DeepSimpleAgent(SimpleAgent):\n",
    "    \"\"\"A greedy agent based on OneShotSyncAgent that does something \n",
    "    when in the middle of the production chain\"\"\"\n",
    "    \n",
    "    def before_step(self):\n",
    "        self._sales = self._supplies = 0\n",
    "        \n",
    "    def on_negotiation_success(self, contract, mechanism):\n",
    "        if contract.annotation[\"product\"] == self.awi.my_input_product:\n",
    "            self._sales += contract.agreement[\"quantity\"]\n",
    "        else:\n",
    "            self._supplies += contract.agreement[\"quantity\"]\n",
    "        \n",
    "    def _needed(self, negotiator_id):\n",
    "        summary = self.awi.exogenous_contract_summary\n",
    "        secured = ( \n",
    "            self._sales \n",
    "            if self._is_selling(self.get_nmi(negotiator_id)) \n",
    "            else self._supplies\n",
    "        )\n",
    "        demand = min(summary[0][0], summary[-1][0]) / (self.awi.n_competitors + 1)     \n",
    "        return  demand - secured"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norwegian-debate",
   "metadata": {
    "papermill": {
     "duration": 0.11728,
     "end_time": "2022-02-16T09:30:46.909628",
     "exception": false,
     "start_time": "2022-02-16T09:30:46.792348",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Firstly, we now keep track of our sales and supplies separately:\n",
    "\n",
    "```python\n",
    "def before_step(self):\n",
    "    self._sales = self._supplies = 0\n",
    "\n",
    "def on_negotiation_success(self, contract, mechanism):\n",
    "    if contract.annotation[\"seller\"] == self.id:\n",
    "        self._sales += contract.agreement[\"quantity\"]\n",
    "    else:\n",
    "        self._supplies += contract.agreement[\"quantity\"]\n",
    "```\n",
    "\n",
    "To find out whether a contract is for sales or supplies, we simply check that the `seller` in the contract annotation is us. \n",
    "\n",
    "We need now one more chanage which is to separate the calculation of our needs for supplies and sales:\n",
    "```python\n",
    "def _needed(self, negotiator_id):\n",
    "    summary = self.awi.exogenous_contract_summary\n",
    "    secured = ( \n",
    "        self._sales \n",
    "        if self._is_selling(self.get_nmi(negotiator_id)) \n",
    "        else self._supplies\n",
    "    )\n",
    "    demand = min(summary[0][0], summary[-1][0]) / (self.awi.n_competitors + 1)     \n",
    "    return  demand - secured\n",
    "```\n",
    "\n",
    "here we start by reading the summary information of exogenous contracts into `summary`. This is a list of two valued tuples giving the **total** quantity and **total** price (in that order) of all current exogenous contracts for all products. We also find the amount we secured (depending on whether this is a buy or a sell negotiation) and the number of competitors (i.e. agents in the same production level as us). We assume that we need to buy (and sell) the same quantity as the minimum of the raw material and final product exogenous contracts divided equally between us and our competitors (we add one to `n_competitors` to count ourselves).\n",
    "\n",
    "Now, let's see how does this agent behave compared with the previous agent in a deep world simulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaging-player",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T09:30:47.130772Z",
     "iopub.status.busy": "2022-02-16T09:30:47.127308Z",
     "iopub.status.idle": "2022-02-16T09:30:59.951385Z",
     "shell.execute_reply": "2022-02-16T09:30:59.949887Z"
    },
    "papermill": {
     "duration": 12.933023,
     "end_time": "2022-02-16T09:30:59.951639",
     "exception": false,
     "start_time": "2022-02-16T09:30:47.018616",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "world, ascores, tscores = try_agents([SyncRandomAgent, DeepSimpleAgent], n_processes=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clean-maple",
   "metadata": {
    "papermill": {
     "duration": 0.105629,
     "end_time": "2022-02-16T09:31:00.155773",
     "exception": false,
     "start_time": "2022-02-16T09:31:00.050144",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Examining the graph above, you can see that `DeepSimple` agents could get contracts when they were in the middle of the production chain. The `Simple` agent on the other hand cannot do so. \n",
    "\n",
    "Agents in the package `scml.oneshot.agents` were designed to work in deep production graphs not only in the first and last layer whenever that is possible.\n",
    "\n",
    "We can check the results now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exciting-education",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T09:31:00.505875Z",
     "iopub.status.busy": "2022-02-16T09:31:00.501792Z",
     "iopub.status.idle": "2022-02-16T09:31:00.510118Z",
     "shell.execute_reply": "2022-02-16T09:31:00.504679Z"
    },
    "papermill": {
     "duration": 0.215208,
     "end_time": "2022-02-16T09:31:00.510481",
     "exception": false,
     "start_time": "2022-02-16T09:31:00.295273",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print_type_scores(tscores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "institutional-process",
   "metadata": {
    "papermill": {
     "duration": 0.159464,
     "end_time": "2022-02-16T09:31:00.781689",
     "exception": false,
     "start_time": "2022-02-16T09:31:00.622225",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Even though our new `DeepSimpleAgent` was able to get contracts which in the middle, it seems that it did worse than `BetterAgent` in terms of final profits. This may be just a quirk of this specific configuration. We will leave it to the reader to investigate this issue (if they choose to)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "least-square",
   "metadata": {
    "papermill": {
     "duration": 0.171513,
     "end_time": "2022-02-16T09:33:11.496344",
     "exception": false,
     "start_time": "2022-02-16T09:33:11.324831",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Comparing all agents\n",
    "\n",
    "Let's run a tournament comparing all agents we developed in this tutorial (we will ignore the do-nothing agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minor-register",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T09:33:11.877000Z",
     "iopub.status.busy": "2022-02-16T09:33:11.875954Z",
     "iopub.status.idle": "2022-02-16T09:37:00.278155Z",
     "shell.execute_reply": "2022-02-16T09:37:00.278604Z"
    },
    "papermill": {
     "duration": 228.602912,
     "end_time": "2022-02-16T09:37:00.278797",
     "exception": false,
     "start_time": "2022-02-16T09:33:11.675885",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# may take a long time\n",
    "_, _, tscores = try_agents(\n",
    "    [\n",
    "        SyncRandomAgent,\n",
    "        SimpleAgent, DeepSimpleAgent,\n",
    "        BetterAgent, LearningAgent,\n",
    "        AdaptiveAgent, NaiveSyncAgent, \n",
    "        SimpleSingleAgreementAgent, \n",
    "        GreedyIndNeg, GeniusIndNeg\n",
    "    ],\n",
    "    n_trials=20,\n",
    "    n_processes=2,\n",
    "    draw=False\n",
    ")\n",
    "print_type_scores(tscores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floating-evening",
   "metadata": {
    "papermill": {
     "duration": 0.118469,
     "end_time": "2022-02-16T09:37:00.517410",
     "exception": false,
     "start_time": "2022-02-16T09:37:00.398941",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The way we just compared these agents is not unbiased because not all agents are allowed to control the same factories in the same simulation envoironment. The best way to compare these agents is to run a tournament between them. You already learned how to do that in the previous tutorial and we will not repeate it here.\n",
    "\n",
    "*If you are running this notebook, please note that the tournament running methods `anac2023_*` may not work within a notebook environment. You can just move your code to a normal python script and it will run correctly*\n",
    "\n",
    "\n",
    "You can find all the agents available in the `scml` package for the one-shot game under `scml.oneshot.agents` including the ones developed in this tutorial (with some modifications):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unusual-buyer",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T09:37:00.689700Z",
     "iopub.status.busy": "2022-02-16T09:37:00.688714Z",
     "iopub.status.idle": "2022-02-16T09:37:00.691912Z",
     "shell.execute_reply": "2022-02-16T09:37:00.692455Z"
    },
    "papermill": {
     "duration": 0.095113,
     "end_time": "2022-02-16T09:37:00.693071",
     "exception": false,
     "start_time": "2022-02-16T09:37:00.597958",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import scml.oneshot.agents as agents\n",
    "pprint([ _ for _ in agents.__dir__() if _.endswith(\"Agent\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd65482a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "scml",
   "language": "python",
   "name": "scml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 558.339002,
   "end_time": "2022-02-16T09:39:07.990953",
   "environment_variables": {},
   "exception": null,
   "input_path": "/Users/yasser/code/projects/scml/notebooks/tutorials/02.develop_agent_scml2020_oneshot.ipynb",
   "output_path": "/Users/yasser/code/projects/scml/notebooks/tutorials/02.develop_agent_scml2020_oneshot.ipynb",
   "parameters": {},
   "start_time": "2022-02-16T09:29:49.651951",
   "version": "2.3.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
